<launch>
<!-- Includes from other ROS packages-->
<include file="$(find azure_kinect_ros_driver)/launch/driver.launch">
    <arg name="color_enabled" value="true"/>
    <arg name="color_resolution" value="1080P"/>
    <arg name="point_cloud" value="true"/>
    <arg name="point_cloud_in_depth_frame" default="true"/>
    <arg name="rgb_point_cloud" value="true"/>
    <arg name="fps" value="5"/>
</include>

<!-- Common arguments -->

<arg name="voxel_size" default="0.01"/>


<!-- Nodes -->

<!-- STEP 1: Apply preprocessing on the data received from Azure Kinect -->
<node pkg="shape_registration" type="preprocessing_node" name="preprocessing" output="screen">
    <param name="pass_through_filter_x_min_range" type="double" value="-0.52"/>
    <param name="pass_through_filter_x_max_range" type="double" value="0.53"/>
    <param name="pass_through_filter_y_min_range" type="double" value="-0.22"/>
    <param name="pass_through_filter_y_max_range" type="double" value="0.11"/>
    <param name="pass_through_filter_z_min_range" type="double" value="0.72"/>
    <param name="pass_through_filter_z_max_range" type="double" value="9.97"/>
    <param name="voxel_grid_filter_voxel_size" type="double" value="$(arg voxel_size)"/>
</node>

<!-- STEP 2 Extract the planar structures from both the CT and the RGBD camera data -->
<node pkg="shape_registration" type="plane_segmentation_node" name="plane_segmentation" output="screen">
    <param name="plane_segmentation_threshold_for_CT" type="double" value="23"/>
    <param name="plane_segmentation_threshold_for_RGBD" type="double" value="0.010"/>
</node>

<!-- STEP 3: Find the transformation between previous and the current frame using ICP -->
<node pkg="shape_registration" type="arm_tracking_node" name="arm_tracking" output="screen">
    <param name="icp_max_num_of_iterations" type="double" value="300"/>
    <param name="voxel_grid_filter_voxel_size" type="double" value="$(arg voxel_size)"/>
</node>

</launch>
